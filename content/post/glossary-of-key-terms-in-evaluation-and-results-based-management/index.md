---
title: "Glossary of Key Terms in Evaluation and Results-Based Management "
subtitle: "2nd Edition – Prepublication version | DAC Network on Development Evaluation "
date: 2023-06-04T12:37:14.302Z
summary: "This Glossary provides conceptual clarity on common terms used in
  results based management, monitoring and evaluation. This 2nd Edition includes
  new terms, as well as updates and improvements to the original Glossary
  published in 2002. It is intended to support thoughtful approaches to
  resultsbased management, monitoring and evaluation, which in turn support
  better progress on sustainable development through learning and
  accountability.   Members of the OECD DAC Network on Development Evaluation
  and the OECD/DAC Results Community of Practice developed the Glossary, under
  the guidance of the OECD Secretariat. The text has benefited from consultation
  with many experts and partners in the broader evaluation and results
  communities, and input from other DAC subsidiary bodies.   Note: This
  English-only prepublication version provides the full English text for
  reference. It will be replaced by the formal trilingual publication following
  translation and formatting."
draft: false
featured: false
image:
  filename: ""
  focal_point: Smart
  preview_only: false
---
### 1﻿. Introduction

This Glossary provides conceptual clarity to support thoughtful approaches to results-based management, monitoring and evaluation, which in turn support better progress on sustainable development through learning and accountability. This glossary is useful for training and in practical work on sustainable development in the public and private sectors – including during project or policy design, monitoring, programme implementation and management, and various types of evaluation.   The focus of the Glossary is on specific terms as used for results monitoring, management, data collection and analysis, and evaluation. We do not define related or general concepts – such as human rights, equity, or development – as these are defined elsewhere and used here in standard, widely accepted ways. Notes define and explain key concepts (and form part of the definitions). Cross-references point the reader to related terms and synonyms.  This second edition of the Glossary reflects learnings and context changes over the past 20 years. It incorporates new thinking from the OECD/DAC Results Community, which did not exist at the time of the first edition in 2002. It includes updates to definitions as well as new terms now in common use. Several definitions have been adjusted to reflect their current use by a range of actors in diverse contexts of work on sustainable development, including within communities. This edition also reflects the extensive work undertaken in 2017-2019 by the OECD Development Assistance Committee’s (DAC) Network on Development Evaluation to refine the definitions of the evaluation criteria originally outlined here in 2002. The adapted criteria definitions approved in 2019 are included in this updated edition.   This process has been guided by the highest considerations of clarity and conciseness. It was conducted in a spirit of compromise in terms of the willingness of partners not to impose their own specific vocabulary on others.   The original Glossary, published in 2002 was the fruit of almost two years of elaboration, based on an initial collection of terms used by development agencies. The selection of terms and their definitions were carefully discussed and analysed, and benefited from inputs from many sources and advice from the academic evaluation community. Likewise, this second edition involved extensive consultation and input from experts and partners across the results and evaluation communities.

### 2 Terms

**Accountability**

Accountability is a state of or a process for holding someone responsible to someone else for something. It is the obligation to demonstrate that work has been conducted in compliance with agreed rules and standards, or to report fairly and accurately on results, based on mandates and plans. This may require a careful, even legally defensible, demonstration that the work is consistent with the terms of a contract.

Note: Accountability may refer to the obligations of parties to act according to clearly defined performance expectations, often with respect to the prudent use of resources. For public sector managers and policy- makers it refers to being accountable to stakeholders such as taxpayers, civil society and communities for what has been done, why and how, including justifying or explaining costs and any negative results. Types of accountability include community accountability, bottom-up accountability, horizontal accountability and top-down accountability.

For evaluators, it connotes the responsibility to provide accurate, fair and credible reports and assessments.

Related terms: community accountability, mutual accountability

**(Community) Accountability**

Holding intervention funders and implementers accountable to the people and community affected by the intervention for the process and results of that intervention.

**(Mutual) Accountability**

Shared responsibility for the intervention implementation and its results. The obligation of two or more partners to demonstrate compliance with mutually agreed rules and standards or to report fairly and accurately on the use of resources and achievement of results for mandated roles or plans. Involves transparent reporting on progress in sustainable development that has been achieved collectively (through contributions from multiple partners) and implications for affected people and other stakeholders.

**Activity**

Actions taken or work performed through which inputs, such as funds, technical assistance and other types of resources, are mobilised to produce specific outputs.

Synonym: intervention Related term: evaluand

**Adaptive management**

A structured management strategy that involves an ongoing process of working collaboratively and flexibly to learn, make decisions, test assumptions, and adjust actions on the basis of new information, lessons and changes in context.

Note: Often used to take action under conditions of ongoing uncertainty based on the best available evidence. Involves systematically monitoring and evaluating results and adjusting decisions as more information is learned.

**Additionality**

The characteristic of an intervention, where its (financial or non-financial) inputs, activities or results are considered as additional when compared to what would have happened otherwise. Additional means larger in scale, at a higher quality, taking place more quickly, at a different location, reaching different beneficiaries, or taking place at all.

Note: In development co-operation many institutions distinguish between financial additionality (in reference to financing provided that would not be supplied by the market), and development additionality (referring to results).

**Administrative data**

Information collected by an intervention for purposes of administration, record keeping and tracking implementation, which can also be used for monitoring and evaluation.
Note: Administrative data typically include financial and operational data at activity level. It is common for basic demographic information to be derived from administrative data. Examples include enrolment records, tax records, insurance claims, feedback forms, and patient records.

**Analytical tool**

Method used to process and interpret data collected or collated.

**Appraisal**

An overall assessment of the relevance, feasibility and potential sustainability of an intervention prior to a decision regarding funding or implementation.

Note: In development agencies, banks, and other financial institutions, the purpose of the appraisal is to enable decision makers to decide whether the activity represents an appropriate use of resources.

Related term: ex-ante evaluation



**Assumptions**

A set of (untested) factors and beliefs that form the basis of the intervention logic, and factors or risks, which affect its relevance, progress or success. Assumptions are the conditions necessary for the cause- and-effect relationships between the different levels of results (i.e. to move from activities to outputs, outputs to outcomes, and outcomes to impacts).

Note: For design, monitoring and evaluation, assumptions can also be understood as hypothesised conditions that affect the validity of the exercise itself, e.g., about the size or characteristics of the population when designing a sampling procedure for a survey.

Related term: hypotheses

**Attribution**

The ascription of a causal link between observed (or expected to be observed) changes and a specific intervention.

Note: Attribution refers to that which is to be credited for the observed changes or results achieved. This definition does not require that changes are produced solely by the intervention being evaluated, rather it represents the extent to which observed effects can be attributed to a specific intervention or to one or more partners, taking account of other interventions, confounding factors (other influences), or external shocks.

**Audit**

An independent, systematic, objective quality assurance assessment designed to document and improve the effectiveness of risk management, control and governance processes.

Note: A distinction is made between regularity (financial) auditing, which focuses on compliance with applicable statutes and regulations; and performance auditing, which is concerned with relevance, efficiency and effectiveness. Internal auditing provides an assessment of internal controls undertaken by a unit reporting to management while external auditing is conducted by an independent entity.

**Baseline (reference value)**

The conditions existing prior to an intervention or at the beginning of the period, against which changes can be measured, monitored and evaluated.

**Baseline study**

An analysis describing the situation prior to an intervention, against which changes can be assessed or comparisons made.

**Benchmark**

A reference point or standard against which changes, performance or achievements can be assessed.

Note: A benchmark is established based on recent performance of comparable organisations, or what can be reasonably inferred to have been achieved under a similar set of circumstances.

**Beneficiaries (People who benefit)**

The individuals, groups, or organisations, whether targeted or not, that benefit, directly or indirectly, from the intervention.

Note: Other terms used, depending on the context, include rights holders, duty bearers, or affected people. It is often useful to refer to “intended” beneficiaries, and one should not assume that all people have equal access to or benefit equally (or at all) from the intervention. In fact evaluations often serve the purpose of investigating the extent to which intended benefits were achieved, for whom and how (including differential benefits across different groups of people).

Related terms: reach, target group

**Causality**

The relationship between one event (the cause) and another event (the effect) which is the direct consequence of the first.

**Cluster evaluation**

An evaluation of a set of related activities or interventions, either similar interventions in different locations or a cluster of complementary components of an overall initiative.

Related terms: thematic evaluation, sector programme evaluation

**Coherence**

The compatibility of the intervention with other interventions in a country, sector or institution.

Note: The extent to which other interventions (particularly policies) support or undermine the intervention, and vice versa. Includes internal coherence and external coherence:

**Internal coherence**
The synergies and interlinkages between the intervention and other interventions carried out by the same institution/government, as well as the consistency of the intervention with the relevant international norms and standards to which that institution/government adheres.

**External coherence**
The consistency of the intervention with other actors’ interventions in the same context. This includes complementarity, harmonisation and co-ordination with others, and the extent to which the intervention is adding value while avoiding duplication of effort.

Related term: policy coherence for sustainable development

Policy coherence for sustainable development

The compatibility of a policy with other policies in a country, sector or institution in terms of supporting sustainable development. The extent to which other policies support or undermine the intervention, and vice versa.

Related term: coherence

**Commissioner**

The person or entity responsible for requesting or ordering an evaluation.

**Conclusions**

A summary of the factors leading to the success or failure of the evaluated intervention. Special attention is paid to the intended and unintended effects, results and impacts, and more generally to any other strength or weakness. A conclusion draws on data collection and analyses undertaken, through a transparent chain of arguments.

**Context**

The setting in which an intervention or an evaluation takes place and which is likely to influence performance and results. These include capacities and social, economic, political, environmental, conflict, inclusiveness, cultural, and institutional conditions.

Contribution – \[definition under discussion]

**Contribution analysis**

An approach for determining if – and how – an intervention contributed to an observed result, based on verifying the underlying theory of change.

**Control group**

The sample or group that does not receive the intervention and against which other groups or samples (that do receive the intervention) are compared in order to assess performance and results.

**Counterfactual**

The situation or condition that hypothetically may prevail for individuals, organisations, or groups were there no intervention (the status quo).

Note: This is used for counterfactual evaluation approaches. It can be estimated by creating a control group, a comparison group or a hypothetical counterfactual.

**Country programme evaluation**

Evaluation of one or more institution’s or partner’s portfolio of interventions in a specific country, including the strategy behind them in a specific period of time.

**Culture of results and learning; Culture of evaluation**

The collective formal and informal norms, beliefs and ways of working in an institution that support and encourage staff and partners to actively seek out, learn from and act on credible results information. A culture that supports and encourages people to critically think about the design, implementation and effects of interventions, including relevance, coherence, efficiency, effectiveness, impact and sustainability. This includes understanding causal relationships, testing assumptions and considering evidence generated internally or by external actors on what works or not, why and for whom, and adjusting actions accordingly.

**Data collection tool**

Methods used to identify information sources and collect information. Examples include informal and formal surveys, direct and participatory observations, community interviews, focus groups, expert opinions, case studies, and literature search.

**Democratic evaluation**

An approach to evaluation that aims to support a just and democratic society and serve the whole community.

Note: Democratic evaluation allows people to be informed of what others are doing and sees the evaluator as someone who brokers the process. It generally uses inclusive practices that foster participation and collaboration to understand progress towards a just and democratic society. Also used as a means of ensuring public accountability and transparency.

**Developmental evaluation**

An iterative, embedded approach to evaluation, designed to support learning particularly in complex or uncertain environments. It involves providing real-time, or near real-time, (independent) feedback to intervention staff, thus facilitating ongoing learning and enabling improvements during implementation.

Related terms: real-time evaluation, adaptive management, ex-ante evaluation 

**Economic**

The conversion of inputs (funds, expertise, natural resources, time, etc.) into outputs, outcomes and impacts in the most cost-effective way possible, as compared to feasible alternatives in the context.

Related term: efficiency

**Economical**

Absence of waste for a given output. An activity is economical when the costs of the scarce resources used approximate the minimum needed to achieve the planned objectives.

Related term: efficiency

**Economic evaluation**

An analysis that quantifies whether the economic benefits of a project (achieved or expected to be achieved) exceed its economic costs. A systematic analysis that assesses the resources used in relation to the results achieved, providing an assessment of cost effectiveness.

Note: Different types of economic analysis include cost-benefit, value for money, cost-effectiveness and cost-utility.

Related term: efficiency

**Effects**

Intended or unintended changes due directly or indirectly to an intervention. Related terms: outputs, outcomes, impacts, results

**Effectiveness**

The extent to which the intervention achieved, or is expected to achieve, its objectives, and its results, including any differential results across groups.

Note: Analysis of effectiveness involves taking account of the relative importance of the objectives or results.

Related terms: efficiency, coherence, relevance, impact, sustainability

**Efficiency**

The extent to which the intervention delivers, or is likely to deliver, results in an economic and timely way.

Note: “Economic” is the conversion of inputs (funds, expertise, natural resources, time, etc.) into outputs, outcomes and impacts in the most cost-effective way possible, as compared to feasible alternatives in the context. “Timely” delivery is within the intended timeframe, or a timeframe reasonably adjusted to the demands of the evolving context. This may include assessing operational efficiency (how well the intervention was managed).

Related terms: effectiveness, coherence, relevance, impact, sustainability

**End line**

The conditions existing after an intervention or end of the period, against which changes from the baseline can be measured, monitored and evaluated.

Related term: baseline

**Evaluability**

Extent to which an intervention can be evaluated in a reliable and credible fashion.

Note: Some approaches to evaluability assessment involve early review of a proposed intervention in order to ascertain whether its objectives are adequately defined and its results are verifiable. In other instances, particularly with complex interventions, high uncertainty or in unstable contexts, evaluability assessment might instead identify a need for an evaluation approach that supports adaptive management (for example, developmental evaluation).

**Evaluand**

The institution or intervention that is being evaluated; the object of the evaluation.

**Evaluation**

The systematic and objective assessment of a planned, ongoing or completed intervention, its design, implementation and results. The aim is to determine relevance, coherence, effectiveness, efficiency, impact

and sustainability. Evaluation also refers to the process of determining the worth or significance of an intervention.

An evaluation should provide information that is credible and useful, enabling the incorporation of lessons learned into decision-making processes.

Note: Evaluation in some instances involves the definition of appropriate standards and criteria, the examination of performance against those standards, an assessment of actual and expected results and the identification of relevant lessons and recommendations. Though evaluation deals with the assessment of relevance, coherence, effectiveness, efficiency, impact and sustainability, not all evaluations will cover all of these criteria to the same degree or at all.

**Evaluation purpose**

The objectives of the evaluation including why the evaluation is being undertaken at this particular point in time, for whom and how the evaluation will be used for learning and accountability.

**Evidence**

Facts or information that support the validity and truth of a conclusion, assumption or assertion.

**Evidence-based (policy, practice)**

Reliable and credible evidence determines the design, adaptation and implementation of a policy or practice.

**Ex-ante evaluation**

An evaluation that is performed before the implementation of an intervention. Related terms: appraisal, quality at entry, evaluability

**Ex-durante evaluation**

An evaluation that is performed during the implementation of an intervention (while it is ongoing).

**Ex-post evaluation**

Evaluation of an intervention after it has been completed.

Note: An ex-post evaluation may be undertaken directly following or some time after the intervention. The intention is to identify the factors of success or failure, to assess the sustainability of results and impacts, and to draw conclusions that may inform other interventions.

**External evaluation**

The evaluation of an intervention conducted by entities or individuals outside the funding and implementing organisations.

Related term: independent evaluation

**Evaluation feedback**

The transmission of findings generated through the evaluation process to parties for whom it is relevant and useful so as to facilitate learning or accountability. This may involve the collection and dissemination of findings, conclusions, recommendations and lessons from experience to people affected by the intervention, as well as funders, implementers, decision makers and other stakeholders.

**Feminist evaluation**

A value-based approach to evaluation grounded in feminist theory and principles, which emphasises empowerment, social justice and participation, as well as understanding structural barriers that prevent equality, while aiming to contribute to transforming gendered power relationships.

Related terms: gender analysis, gender-responsive evaluation, human rights-based evaluation, participatory evaluation

**Finding**

A finding uses evidence from one or more evaluations to allow for a factual statement.

**Formative evaluation**

Evaluation intended to improve performance or to inform planning of a subsequent phase, often conducted during the implementation phase of the intervention.

Note: Formative evaluations may also be conducted for other reasons such as compliance, legal requirements or as part of a larger evaluation initiative.

Related terms: process evaluation, developmental evaluation

**Gender analysis**

An examination of gender dynamics, norms, beliefs and practices, including concepts of masculinity, femininity, and other gender identities, and power relationships among people of different genders.

Note: For planning, monitoring and evaluation, gender analysis can be used to understand the intervention and its context, as well as for analysing the results of the intervention and for making evaluative judgements.

**Gender-responsive evaluation**

An evaluation that assesses changes to gendered power relationships and results from an intervention, determining whether, and how, changes have occurred, and the effects of those changes. The approach to the evaluation ensures that the voices of people of different genders are incorporated throughout the process and in the methods used.

**Goal**

The higher-order objective to which an intervention is intended to contribute. Note: An example is the 2030 Sustainable Development Goals (SDGs).
Related term: objective

**Human rights-based evaluation**

An evaluation approach that explicitly identifies rights-holders and duty-bearers, and aims to hold duty- bearers to account for the realisation of human rights. The evaluation applies human rights principles to its approach, including through participation of rights-holders in the evaluation process itself, and explores issues of justice, equity and equality with a focus on marginalised and excluded groups.

**Hypotheses**

A set of (testable) ideas, beliefs and explanations about the relationship between an intervention and its effects, in a given context.

Related terms: assumptions, theory of change, intervention logic

**Impact**

The extent to which the intervention has generated or is expected to generate significant positive or negative, intended or unintended, higher-level effects.

Note: Impact addresses the ultimate significance and potentially transformative effects of the intervention. It seeks to identify social, environmental and economic effects of the intervention that are longer term or broader in scope than those already captured under the effectiveness criterion. Beyond the immediate results, impact seeks to capture the indirect, secondary and potential consequences of the intervention. It does so by examining the holistic and enduring changes in systems or norms, and potential effects on people’s well-being, human rights, gender equality, and the environment.

Related terms: relevance, coherence, effectiveness, efficiency, sustainability

**Impacts**

The higher-level effects of an intervention’s outcomes. The ultimate effects or longer-term changes resulting from the intervention. Such impacts can include intended and unintended, positive or negative higher-level effects.

Note: Impacts is used here in the plural in reference to its meaning as a type or level of result, as distinct from the impact criterion. “Impacts” and “results” are sometimes used interchangeably, which creates confusion; impacts should be used to refer to higher-level results.

Related term: transformative effects

**Impact evaluation**

An evaluation that assesses the degree to which the intervention meets its higher-level goals and identifies the causal effects of the intervention. Impact evaluations may use experimental, quasi-experimental and non-experimental approaches.

Note: The term is also sometimes used to refer only to evaluations that use explicit counterfactual analysis to determine the effects (including outputs and outcomes) caused by an intervention.

**Impact management**

A management strategy focusing on performance and achievement of impacts. This management approach provides the framework, tools and guidance for strategic planning, risk management, performance monitoring, evaluation and knowledge management. It serves four complementary purposes: decision- making, learning, accountability and communication.

Synonym: results-based management

**Independent evaluation**

An evaluation that is free from undue political influence and organisational pressure, which has full access to information and autonomy to carry out investigations and reports findings and conclusions based on the collected evidence.

Note: Independence is often supported by having external individuals or institutions carry out the evaluation. Independence can also be supported through funding arrangements, reporting lines and quality assurance processes. The credibility of an evaluation depends in part on how independently it has been carried out, including the extent to which it is free from the potential biases of those responsible for the design and implementation of the intervention.

**Indicator**

Quantitative or qualitative factor or variable of interest, related to the intervention and its results, or to the context in which an intervention takes place.

Note: An indicator is always approximate only (i.e. not an exact measure) and requires interpretation and explanation, even if assessed accurately. Indicators should provide simple, verifiable, and reliable means to track changes and performance.

Related terms: KPI, performance indicator

**Inputs**

The financial, human, material (in-kind), and institutional (including technological and information) resources used for the intervention.

Note: It is important to include not only the resources of a funding or implementing organisation but the totality of resources of all involved organisations, the community and the local environment used for the intervention.

**Institutional development impact**

The extent to which an intervention improves or weakens the ability of a country or region to make more efficient, equitable, and sustainable use of its human, financial, and natural resources, for example through:
(a) better definition, stability, transparency, enforceability and predictability of institutional arrangements, or 

(b) better alignment of the mission and capacity of an organisation with its mandate, which derives from these institutional arrangements. Such impacts can include intended and unintended effects of an action.

**Internal evaluation**

Evaluation of an intervention conducted by a unit or individuals internal to the organisation, generally staff of the organisation who report to the management.

Related term: self-evaluation

**Intervention**

The intentional activity or effort that is being evaluated (also called the evaluand or object of the monitoring or evaluation).

Note: Interventions may be international, national, local or through partnerships, and are aimed at supporting sustainable development, climate and humanitarian goals. They include but are not limited to development interventions, humanitarian aid, peacebuilding activities, climate mitigation activities, climate adaptation activities, market-based interventions, private sector engagement, normative work, and non-sovereign operations. Examples of such efforts include strategies, policy advice, technical assistance, financing mechanisms, programmes, institutions, or projects.

Synonym: evaluand Related term: activity

**Intervention logic**

The way an intervention is expected to achieve its desired results, including underlying assumptions about the causality and interaction between the intervention, its inputs, activities, outputs, outcomes and impacts, in the context of the intervention.
Related terms: logical framework, theory of change, assumptions

**Intervention purpose**

The stated (or implied) objectives of the intervention. Related terms: intervention objective, goal

**Joint evaluation**

An evaluation in which two or more institutions or partners participate.

Note: There are various degrees of “jointness” depending on the extent to which individual partners are involved in designing the evaluation, co-operate in the evaluation process, merge their evaluation resources and combine their evaluation reporting. Joint evaluations can help overcome attribution problems in assessing the effectiveness of programmes and strategies. They can also be useful for evaluating coherence, looking at the complementarity of efforts supported by different partners, the quality of co-ordination, etc.

**Knowledge management**

The process or approach through which institutions capture, distribute, retain and effectively use knowledge to achieve their goals.

**Lessons learnt**

Generalisation or extrapolation of findings and translation of analysis into relevant knowledge that supports decision making, improves performance and promotes the achievement of better results in other settings (beyond the intervention being evaluated). Frequently, lessons highlight strengths or weaknesses in the preparation, design, and implementation of interventions that affect performance and results. A lesson may be positive, neutral or negative.

**Limitations**

Any constraints in the process, methodology or data that affect the monitoring or evaluation, including potential implications for validity and reliability. Includes any obstruction of a free and open monitoring and evaluation process that may influence the findings, as well as discrepancies between the planned and actual products or process.

**Logical framework (Log frame)**

Management tool used to improve the design of interventions, most often at the project level. It involves identifying strategic elements (inputs, activities, outputs, outcomes, impacts) and their causal relationships, as well as indicators, and the assumptions or risks that may influence success and failure. It facilitates planning, execution, monitoring and evaluation of an intervention.

Related terms: results-based management, theory of change, intervention logic

**Meta-evaluation**

The term is used for evaluations designed to synthesise findings from a series of evaluations. It can also be used to denote the assessment of an evaluation to judge its quality or scrutinise the performance of the evaluators.

**Mid-term evaluation**

Evaluation performed towards the middle of the period of implementation of the intervention. Related terms: formative evaluation, developmental evaluation.

**Monitoring**

A continuing process that involves the systematic collection or collation of data (on specified indicators or other types of information). Provides the management and other stakeholders of an intervention with indications of the extent of implementation progress, achievement of intended results, occurrence of unintended results, use of allocated funds and other important intervention and context-related information.

Related terms: performance monitoring, performance indicator, indicator

**Objective (Sustainable development objective)**

Intended positive impacts contributing to physical, financial, institutional, social, well-being, environmental, or other benefits to a society, community, or group of people via one or more interventions.

**Related term: intervention objective**

Intervention objective

The overall purpose of an intervention. This includes the intended physical, financial, institutional, social, environmental, or other results that an intervention is expected to achieve or to which it is expected to contribute.

Related terms: intervention purpose, goal

**Outcomes**

The short-term and medium-term effects of an intervention’s outputs.

Note: Outcomes are often changes in the institutional and behavioural capacities for development conditions that occur between the completion of outputs and the achievement of impacts.

Related terms: results, outputs, impacts, effect.

**Outputs**

The products, capital goods and services that result from an intervention. Outputs may also include changes resulting from the intervention that contribute to the achievement of outcomes. Outputs include changes in knowledge, skills, or abilities produced by the activities.

Note: Outputs are within the control of the implementing team and attributable to it. Related term: results

**Participatory monitoring and evaluation**

An evaluation approach in which partners (including target groups) work together and are actively involved in monitoring and evaluation including designing plans, collecting and interpreting data, documenting and using findings, and formulating conclusions and recommendations.

**Partner**

An individual or organisation that collaborates on an intervention to achieve mutually agreed objectives.

Note: The concept of partnership connotes shared goals, common responsibility for outcomes, distinct accountabilities and reciprocal obligations. Partners may include communities, governments (national regional, local), civil society organisations, non-governmental organisations, universities, professional and

business associations, private entities, and multi-lateral organisations involved in funding, implementing or overseeing the intervention.

**Performance**

The degree to which an intervention or partner operates according to specific criteria, standards and guidelines, or achieves results in accordance with stated goals or plans.

**Performance indicator**

Quantitative or qualitative factor or variable that provides a simple, verifiable, and reliable means to measure the performance of an actor, generally in terms of the process of implementation.

Related terms: KPI, indicator

**Key Performance Indicator (KPI)**

A subset of indicators that are considered to be the most important to achieving goals, and used to monitor progress, in an ongoing way.

Related terms: indicator, performance

**Performance measurement**

A system for assessing performance of interventions against stated goals. Related terms: performance monitoring, performance indicator, indicator.

**Performance monitoring**

A continuous process of collecting and analysing data to compare how well an intervention is being implemented against expected results.

Related term: performance measurement

**Performance measurement framework**

The performance measurement framework is a results-based management tool used to systematically plan the collection of relevant data over the lifetime of the project, in order to assess and demonstrate progress made in achieving expected results. The performance measurement framework is the “skeleton” of the monitoring plan: it documents the major elements of the monitoring system in order to ensure regular collection of actual data on the performance measurement framework indicators. The performance measurement framework contains all of the indicators used to measures progress on the achievement of the project’s results.

In addition, it specifies who is responsible for collecting data on the indicator, from what source, at what frequency and with what method. It also includes the baseline data and target for each indicator.

Related term: results framework

**Population**

The total universe of persons or institutions in the context in which the intervention takes place; all potential targets of the intervention.

Note: The target group of an intervention is a subset of the population Related terms: target group, people who benefit, stakeholders

**Process evaluation**

An evaluation of the internal dynamics of implementing organisations, their policy instruments, their service delivery mechanisms, their management practices, and the linkages among these.

Related term: formative evaluation

**Programme evaluation**

Evaluation of a set of interventions, combined to attain specific global, regional, country, or sector development objectives.

Note: a development programme is a time-bound intervention involving multiple activities that may cut across sectors, themes and geographic areas.

Related term: country programme evaluation.

**Project evaluation**

Evaluation of an individual intervention designed to achieve specific objectives within specified resources and implementation schedules, often within the framework of a broader programme, examining its relevance, coherence, effectiveness, efficiency, impact and sustainability.

Note: Cost-benefit analysis is one instrument often used in project evaluation for projects with measurable benefits. When benefits cannot be quantified, cost effectiveness is a suitable approach.

**Quality assurance**

Any activity or process that is used to assess and improve the merit or the worth of an intervention or its compliance with given standards and requirements.

Note: Examples of quality assurance activities include appraisal, results-based management, reviews, and evaluations. Quality assurance may also refer to the assessment of the quality of a portfolio and its overall effectiveness.

**Quality at entry**

The strength of the intervention implementation and results, at the time it is designed or before it starts, in terms of its potential relevance, effectiveness, coherence, efficiency, impact and sustainability.

Note: Quality at entry may also be a factor of the extent to which the intervention design is evidence- informed, including the involvement of stakeholders in the conceptualisation of the intervention.

Related terms: evaluability, ex-ante evaluation

**Randomised Control Trial (RCT)**

A type of evaluation that randomly assigns access to the intervention, in order to control influencing variables and limit bias, generating internally valid estimates of results.

**Reach**

The people affected by an intervention, as a subset of the total population. Related terms: people who benefit, target group, population

**Real-time evaluation (real-time learning)**

A process that provides immediate (independent) evaluative evidence, insights and feedback to inform decision making, learning and implementation while the intervention is underway.

Related term: monitoring

**Recommendations**

Proposals aimed at enhancing the relevance, coherence, effectiveness, efficiency, impact or sustainability of the intervention; at redesigning the objectives; or reallocating resources. Recommendations should be based on findings and conclusions.

**Relevance**

The extent to which the intervention objectives and design respond to beneficiaries, global, country, and partner/institution needs, policies, and priorities, and continue to do so if circumstances change.

Note: “Respond to” means that the objectives and design of the intervention are sensitive to the economic, environmental, equity, social, political economy, and capacity conditions in which it takes place. “Partner/institution” includes government (national, regional, local), civil society organisations, private entities and international bodies involved in funding, implementing and/or overseeing the intervention. Relevance assessment involves looking at differences and trade-offs between different priorities or needs. It requires analysing any changes in the context to assess the extent to which the intervention can be (or has been) adapted to remain relevant.

**Reliability**

Consistency or dependability of data and evaluation judgements, with reference to the quality of the instruments, procedures and analyses used to collect and interpret results and evaluation data.

Note: Evaluation and results information is reliable when repeated observations using similar instruments under similar conditions produce similar results.

**Results**

The outputs, outcomes or impacts (intended or unintended, positive or negative) of an intervention. Related terms: outputs, outcomes, effects, impacts

**Results chain**

The causal sequence of an intervention that stipulates the different stages leading to the achievement of the desired objectives. In general, the results chain starts with inputs, which then link to activities and outputs, and culminate in outcomes, and impacts. In some cases, reach is included as part of the results chain.

Related terms: inputs, activities, outputs, outcomes, impact, results framework, theory of change, performance measurement framework

**Results framework**

Explicit articulation (typically, in a graphical or tabular manner) of how a strategy or intervention will achieve the objective(s), including causal relationships and underlying assumptions and risks.

Note: Generally, includes indicators (with baseline, data source, means of verification, etc. for each) for the full results chain: inputs, activities, outputs, outcomes and impacts. In some instances, results frameworks only describe the desired outputs, outcomes and impacts, leaving flexibility to define the inputs and activities that will lead to these results.

Related terms: results chain, logical framework, theory of change, intervention logic.

**Results information**

Qualitative or quantitative data about the outputs, outcomes or impacts (intended or unintended, positive or negative) of an intervention.

Related terms: indicator; result, performance indicator

**Results-Based Management (RBM)**

A management strategy focusing on performance and achievement of outputs, outcomes and impacts. This management approach provides the framework, tools and guidance for strategic planning, risk management, performance monitoring, evaluation and knowledge management. It serves four complementary purposes: decision-making, learning, accountability and communication.

Note: RBM is often a participatory and team-based management approach designed to improve programme delivery and strengthen management effectiveness, efficiency, learning and accountability.

**Review**

An assessment of the performance of an intervention, periodically or on an ad hoc basis.

Note: Sometimes the terms “review” and “evaluation” are used as synonyms. However an evaluation is generally a more systematic and comprehensive assessment than a review. Reviews tend to emphasise operational aspects.

Related term: evaluation

**Risk analysis**

An analysis or an assessment of factors that affect or are likely to affect the achievement of an intervention’s objectives. A detailed examination of the potential unwanted and negative consequences to human life, health, property, or the environment posed by an intervention; a systematic process to provide information regarding such undesirable consequences; the process of quantification of the probabilities and expected impacts for identified risks.

**Rubric**

A framework that sets out criteria and standards for different levels of performance and describes what performance would look like at each level, as a way of answering evaluative questions. It also includes guidance on how to synthesise evidence to form an overall evaluative conclusion.

**Sample**

A subset of a given population which is chosen in such a way as to allow extrapolation of findings to the population.
Note: Extrapolation can be done statistically for random sampling and analytically for purposeful sampling.
Related terms: counter-factual, population

**Scope of the evaluation**

The time period, funds, geographical area, target group(s), organisational set-up, implementation arrangements, policy and institutional context, and other dimensions covered by the evaluation.
Note: The scope of the evaluation should be delineated along at least four levels: operational (all or part of the areas of intervention, one or more related policies or interventions), institutional (all or part of the

authorities), temporal (period taken into account) and geographic (one or more territories or parts of territories, a specific, region, city, place, etc.).

**Sector programme evaluation**

Evaluation of a cluster of interventions within one country or across countries, all of which contribute to the achievement of a specific goal.

Note: a sector includes development activities commonly grouped together for the purpose of public action such as health, education, agriculture, transport, etc.

**Self-evaluation**

An evaluation of an intervention by those who are responsible for its design and delivery. Related term: internal evaluation

Social impact evaluation (social impact assessment)

An evaluation that determines (ex-ante or ex-post) the likely or actual social effects of an intervention. Involves the intended and unintended social consequences, both positive and negative, of interventions and any social change processes affected by the intervention.

**Stakeholders**

Agencies, organisations, groups or individuals who have a direct or indirect interest in the intervention or its monitoring and evaluation.

**Strategic evaluation**

An evaluation that examines how priorities are formulated, looking at overall systems and trends affecting performance and results.

**Summative evaluation**

A study conducted at the end of an intervention (or a phase of that intervention) to determine the extent to which anticipated outcomes were produced. Summative evaluation is intended to provide information about the worth or significance of the intervention.

**Sustainability**

The extent to which the net benefits of the intervention continue, or are likely to continue.

Note: Includes an examination of the financial, economic, social, environmental, and institutional capacities of the systems needed to sustain net benefits over time. Involves analyses of resilience, risks and potential trade-offs. Depending on the timing of the evaluation, this may involve analysing the actual flow of net benefits or estimating the likelihood of net benefits continuing over the medium and long term.

**Target**

An objective, usually quantitative, defined as a value on an established indicator. The target is generally set at the beginning of an intervention and is expected to be achieved by a specific point in time with available resources.
Related term: performance indicator

**Target group**

The specific individuals, communities or organisations that the intervention is intended to reach.

Note: Can also be defined as the recipients of the goods and services produced by the intervention, or whose skills or capacities have changed because of the intervention. The target group may or may not be the individuals or organisations that, ultimately, are intended to benefit from the intervention.

Related term: reach

**Terms of reference**

Written document presenting the purpose and scope of the evaluation, the methods to be used, the standard against which performance is to be assessed or analyses are to be conducted, the resources and time allocated, and reporting requirements.

Note: Two alternative expressions sometimes used are “scope of work” and “evaluation mandate”.

**Thematic evaluation**

Evaluation of a selection of interventions, all of which address a specific sustainable development priority or topic, that cuts across countries, regions, and sectors.

Note: Often thematic evaluations will examine a strategic approach or priority topic across a variety of interventions. An example would be evaluating the extent to which the rights of people with disabilities were advanced across a portfolio of interventions in education, health and employment.

**Theory of change**

The way the intervention is expected to achieve or achieves change. It represents how people understand change to occur in a given context, including explicit (or implicit) assumptions about the causal links between inputs, activities and results. Often also includes evidence and risks for these elements of the results chain.

Related terms: intervention logic, logical framework, results chain, assumptions

**Transformative effects**

Holistic and enduring changes in systems or norms. Related term: impacts

**Triangulation**

The use of three or more theories, sources or types of information, or types of analysis to verify and substantiate an assessment.

Note: Seeks to overcome the bias that comes from single informants, single methods, single observers or single theory studies by combining multiple data sources, methods, analyses or theories, monitoring and evaluation.

**Validity**

The extent to which an evaluation is logically and factually sound. Also used to describe the quality of data collection strategies and instruments to accurately measure what they purport to measure.

\------------------ END --------------------------